{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import urlencode\n",
    "import urllib3\n",
    "import string\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://csdl-api.computer.org/api/v1/graphql (GraphiQL 주소)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Periocials\n",
    "#idPrefix와 title, 그리고 yearFrom,yearTo를 얻을 수 있다.\n",
    "query {\n",
    "  periodicals(pubType:\"journal\") {\n",
    "    idPrefix\n",
    "    title\n",
    "    yearFrom\n",
    "    yearTo\n",
    "  }\n",
    "}\n",
    "\n",
    "#year(month)별 volume\n",
    "query {\n",
    "  periodicalIssues(idPrefix:\"ci\") {\n",
    "    label\n",
    "    issueNum\n",
    "    volume\n",
    "    year\n",
    "  }\n",
    "}\n",
    "\n",
    "#idPrefix, year, issueNum을 통해 article 크롤링\n",
    "query {\n",
    "  articles(idPrefix: \"cc\", year: \"2018\", issueNum: \"02\") {\n",
    "    idPrefix\n",
    "    id\n",
    "    year\n",
    "    pubDate\n",
    "    keywords\n",
    "    title\n",
    "    abstract\n",
    "    authors {\n",
    "      affiliation\n",
    "      fullName\n",
    "      givenName\n",
    "      surname\n",
    "    }\n",
    "    #catalog\n",
    "    #contentType\n",
    "    #pages\n",
    "    #pubType\n",
    "    #sectionTitle\n",
    "    #volume\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Periodicals로 idPrefix, title, yearFrom, yearTo 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.post(\"https://csdl-api.computer.org/api/v1/graphql\", \n",
    "                      json={\n",
    "                          \"query\":'query { periodicals(pubType:\"journal\") { idPrefix title yearFrom yearTo } }'\n",
    "                      })\n",
    "body = resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": {\n",
      "        \"periodicals\": [\n",
      "            {\n",
      "                \"idPrefix\": \"cq\",\n",
      "                \"title\": \"Colloquium\",\n",
      "                \"yearFrom\": 2017,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"dc\",\n",
      "                \"title\": \"IEEE Journal on Exploratory Solid-State Computational Devices and Circuits\",\n",
      "                \"yearFrom\": 2015,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ta\",\n",
      "                \"title\": \"IEEE Transactions on Affective Computing\",\n",
      "                \"yearFrom\": 2010,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"bd\",\n",
      "                \"title\": \"IEEE Transactions on Big Data\",\n",
      "                \"yearFrom\": 2015,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"cc\",\n",
      "                \"title\": \"IEEE Transactions on Cloud Computing\",\n",
      "                \"yearFrom\": 2013,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ci\",\n",
      "                \"title\": \"IEEE Transactions on Computational Intelligence and AI in Games\",\n",
      "                \"yearFrom\": 2009,\n",
      "                \"yearTo\": 2017\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"tc\",\n",
      "                \"title\": \"IEEE Transactions on Computers\",\n",
      "                \"yearFrom\": 1968,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"tq\",\n",
      "                \"title\": \"IEEE Transactions on Dependable and Secure Computing\",\n",
      "                \"yearFrom\": 2004,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ec\",\n",
      "                \"title\": \"IEEE Transactions on Emerging Topics in Computing\",\n",
      "                \"yearFrom\": 2013,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"th\",\n",
      "                \"title\": \"IEEE Transactions on Haptics\",\n",
      "                \"yearFrom\": 2008,\n",
      "                \"yearTo\": 2017\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"tk\",\n",
      "                \"title\": \"IEEE Transactions on Knowledge & Data Engineering\",\n",
      "                \"yearFrom\": 1989,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"lt\",\n",
      "                \"title\": \"IEEE Transactions on Learning Technologies\",\n",
      "                \"yearFrom\": 2008,\n",
      "                \"yearTo\": 2017\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"tm\",\n",
      "                \"title\": \"IEEE Transactions on Mobile Computing\",\n",
      "                \"yearFrom\": 2002,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"mc\",\n",
      "                \"title\": \"IEEE Transactions on Multi-Scale Computing Systems\",\n",
      "                \"yearFrom\": 2015,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"tn\",\n",
      "                \"title\": \"IEEE Transactions on Network Science and Engineering\",\n",
      "                \"yearFrom\": 2014,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"td\",\n",
      "                \"title\": \"IEEE Transactions on Parallel & Distributed Systems\",\n",
      "                \"yearFrom\": 1990,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"tp\",\n",
      "                \"title\": \"IEEE Transactions on Pattern Analysis & Machine Intelligence\",\n",
      "                \"yearFrom\": 1979,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"sc\",\n",
      "                \"title\": \"IEEE Transactions on Services Computing\",\n",
      "                \"yearFrom\": 2008,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ts\",\n",
      "                \"title\": \"IEEE Transactions on Software Engineering\",\n",
      "                \"yearFrom\": 1975,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"su\",\n",
      "                \"title\": \"IEEE Transactions on Sustainable Computing\",\n",
      "                \"yearFrom\": 2016,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"si\",\n",
      "                \"title\": \"IEEE Transactions on Very Large Scale Integration (VLSI) Systems\",\n",
      "                \"yearFrom\": 1993,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"tg\",\n",
      "                \"title\": \"IEEE Transactions on Visualization & Computer Graphics\",\n",
      "                \"yearFrom\": 1995,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"tb\",\n",
      "                \"title\": \"IEEE/ACM Transactions on Computational Biology and Bioinformatics\",\n",
      "                \"yearFrom\": 2004,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"nt\",\n",
      "                \"title\": \"IEEE/ACM Transactions on Networking\",\n",
      "                \"yearFrom\": 1993,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"title\": \"IEEE Computer Architecture Letters\",\n",
      "                \"yearFrom\": 2002,\n",
      "                \"yearTo\": 2018\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"lc\",\n",
      "                \"title\": \"IEEE Letters of the Computer Society\",\n",
      "                \"yearFrom\": 2018,\n",
      "                \"yearTo\": 2018\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(body, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "journals = [] # (title, idPrefix, yearFrom, yearTo)\n",
    "\n",
    "for i in range(0,len(body[\"data\"][\"periodicals\"])):\n",
    "    journals.append( ( (body[\"data\"][\"periodicals\"][i]['title']), body[\"data\"][\"periodicals\"][i]['idPrefix'], body[\"data\"][\"periodicals\"][i]['yearFrom'], body[\"data\"][\"periodicals\"][i]['yearTo']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Colloquium', 'cq', 2017, 2018),\n",
       " ('IEEE Journal on Exploratory Solid-State Computational Devices and Circuits',\n",
       "  'dc',\n",
       "  2015,\n",
       "  2018),\n",
       " ('IEEE Transactions on Affective Computing', 'ta', 2010, 2018),\n",
       " ('IEEE Transactions on Big Data', 'bd', 2015, 2018),\n",
       " ('IEEE Transactions on Cloud Computing', 'cc', 2013, 2018),\n",
       " ('IEEE Transactions on Computational Intelligence and AI in Games',\n",
       "  'ci',\n",
       "  2009,\n",
       "  2017),\n",
       " ('IEEE Transactions on Computers', 'tc', 1968, 2018),\n",
       " ('IEEE Transactions on Dependable and Secure Computing', 'tq', 2004, 2018),\n",
       " ('IEEE Transactions on Emerging Topics in Computing', 'ec', 2013, 2018),\n",
       " ('IEEE Transactions on Haptics', 'th', 2008, 2017),\n",
       " ('IEEE Transactions on Knowledge & Data Engineering', 'tk', 1989, 2018),\n",
       " ('IEEE Transactions on Learning Technologies', 'lt', 2008, 2017),\n",
       " ('IEEE Transactions on Mobile Computing', 'tm', 2002, 2018),\n",
       " ('IEEE Transactions on Multi-Scale Computing Systems', 'mc', 2015, 2018),\n",
       " ('IEEE Transactions on Network Science and Engineering', 'tn', 2014, 2018),\n",
       " ('IEEE Transactions on Parallel & Distributed Systems', 'td', 1990, 2018),\n",
       " ('IEEE Transactions on Pattern Analysis & Machine Intelligence',\n",
       "  'tp',\n",
       "  1979,\n",
       "  2018),\n",
       " ('IEEE Transactions on Services Computing', 'sc', 2008, 2018),\n",
       " ('IEEE Transactions on Software Engineering', 'ts', 1975, 2018),\n",
       " ('IEEE Transactions on Sustainable Computing', 'su', 2016, 2018),\n",
       " ('IEEE Transactions on Very Large Scale Integration (VLSI) Systems',\n",
       "  'si',\n",
       "  1993,\n",
       "  2018),\n",
       " ('IEEE Transactions on Visualization & Computer Graphics', 'tg', 1995, 2018),\n",
       " ('IEEE/ACM Transactions on Computational Biology and Bioinformatics',\n",
       "  'tb',\n",
       "  2004,\n",
       "  2018),\n",
       " ('IEEE/ACM Transactions on Networking', 'nt', 1993, 2018),\n",
       " ('IEEE Computer Architecture Letters', 'ca', 2002, 2018),\n",
       " ('IEEE Letters of the Computer Society', 'lc', 2018, 2018)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PeriodicalIssues로 year, volume, issueNum 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예시\n",
    "resp = requests.post(\"https://csdl-api.computer.org/api/v1/graphql\", \n",
    "                      json={\n",
    "                          \"variables\":{\"idPrefix\":\"ci\"}, #ci는 하나의 예시임. 실제로는 모든 idPrefix 넣으면서 긁어오기\n",
    "                          \"query\":'query ($idPrefix : String!) { periodicalIssues(idPrefix : $idPrefix) { label issueNum volume year } }'\n",
    "                      })\n",
    "body = resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": {\n",
      "        \"periodicalIssues\": [\n",
      "            {\n",
      "                \"label\": \"March\",\n",
      "                \"issueNum\": \"01\",\n",
      "                \"volume\": \"1\",\n",
      "                \"year\": \"2009\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"June\",\n",
      "                \"issueNum\": \"02\",\n",
      "                \"volume\": \"1\",\n",
      "                \"year\": \"2009\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Sept.\",\n",
      "                \"issueNum\": \"03\",\n",
      "                \"volume\": \"1\",\n",
      "                \"year\": \"2009\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Dec.\",\n",
      "                \"issueNum\": \"04\",\n",
      "                \"volume\": \"1\",\n",
      "                \"year\": \"2009\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"March\",\n",
      "                \"issueNum\": \"01\",\n",
      "                \"volume\": \"2\",\n",
      "                \"year\": \"2010\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"June\",\n",
      "                \"issueNum\": \"02\",\n",
      "                \"volume\": \"2\",\n",
      "                \"year\": \"2010\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Sept.\",\n",
      "                \"issueNum\": \"03\",\n",
      "                \"volume\": \"2\",\n",
      "                \"year\": \"2010\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Dec.\",\n",
      "                \"issueNum\": \"04\",\n",
      "                \"volume\": \"2\",\n",
      "                \"year\": \"2010\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"March\",\n",
      "                \"issueNum\": \"01\",\n",
      "                \"volume\": \"3\",\n",
      "                \"year\": \"2011\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"June\",\n",
      "                \"issueNum\": \"02\",\n",
      "                \"volume\": \"3\",\n",
      "                \"year\": \"2011\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Sept.\",\n",
      "                \"issueNum\": \"03\",\n",
      "                \"volume\": \"3\",\n",
      "                \"year\": \"2011\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Dec.\",\n",
      "                \"issueNum\": \"04\",\n",
      "                \"volume\": \"3\",\n",
      "                \"year\": \"2011\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"March\",\n",
      "                \"issueNum\": \"01\",\n",
      "                \"volume\": \"4\",\n",
      "                \"year\": \"2012\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"June\",\n",
      "                \"issueNum\": \"02\",\n",
      "                \"volume\": \"4\",\n",
      "                \"year\": \"2012\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Sept.\",\n",
      "                \"issueNum\": \"03\",\n",
      "                \"volume\": \"4\",\n",
      "                \"year\": \"2012\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Dec.\",\n",
      "                \"issueNum\": \"04\",\n",
      "                \"volume\": \"4\",\n",
      "                \"year\": \"2012\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"March\",\n",
      "                \"issueNum\": \"01\",\n",
      "                \"volume\": \"5\",\n",
      "                \"year\": \"2013\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"June\",\n",
      "                \"issueNum\": \"02\",\n",
      "                \"volume\": \"5\",\n",
      "                \"year\": \"2013\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Sept.\",\n",
      "                \"issueNum\": \"03\",\n",
      "                \"volume\": \"5\",\n",
      "                \"year\": \"2013\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Dec.\",\n",
      "                \"issueNum\": \"04\",\n",
      "                \"volume\": \"5\",\n",
      "                \"year\": \"2013\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"March\",\n",
      "                \"issueNum\": \"01\",\n",
      "                \"volume\": \"6\",\n",
      "                \"year\": \"2014\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"June\",\n",
      "                \"issueNum\": \"02\",\n",
      "                \"volume\": \"6\",\n",
      "                \"year\": \"2014\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Sept.\",\n",
      "                \"issueNum\": \"03\",\n",
      "                \"volume\": \"6\",\n",
      "                \"year\": \"2014\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Dec.\",\n",
      "                \"issueNum\": \"04\",\n",
      "                \"volume\": \"6\",\n",
      "                \"year\": \"2014\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"March\",\n",
      "                \"issueNum\": \"01\",\n",
      "                \"volume\": \"7\",\n",
      "                \"year\": \"2015\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"June\",\n",
      "                \"issueNum\": \"02\",\n",
      "                \"volume\": \"7\",\n",
      "                \"year\": \"2015\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Sept.\",\n",
      "                \"issueNum\": \"03\",\n",
      "                \"volume\": \"7\",\n",
      "                \"year\": \"2015\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Dec.\",\n",
      "                \"issueNum\": \"04\",\n",
      "                \"volume\": \"7\",\n",
      "                \"year\": \"2015\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"March\",\n",
      "                \"issueNum\": \"01\",\n",
      "                \"volume\": \"8\",\n",
      "                \"year\": \"2016\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"June\",\n",
      "                \"issueNum\": \"02\",\n",
      "                \"volume\": \"8\",\n",
      "                \"year\": \"2016\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Sept.\",\n",
      "                \"issueNum\": \"03\",\n",
      "                \"volume\": \"8\",\n",
      "                \"year\": \"2016\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Dec.\",\n",
      "                \"issueNum\": \"04\",\n",
      "                \"volume\": \"8\",\n",
      "                \"year\": \"2016\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"March\",\n",
      "                \"issueNum\": \"01\",\n",
      "                \"volume\": \"9\",\n",
      "                \"year\": \"2017\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"June\",\n",
      "                \"issueNum\": \"02\",\n",
      "                \"volume\": \"9\",\n",
      "                \"year\": \"2017\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Sept.\",\n",
      "                \"issueNum\": \"03\",\n",
      "                \"volume\": \"9\",\n",
      "                \"year\": \"2017\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"PrePrints\",\n",
      "                \"issueNum\": \"01\",\n",
      "                \"volume\": null,\n",
      "                \"year\": \"5555\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(body, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress : 1 of 26 (cq)\n",
      "Progress : 2 of 26 (dc)\n",
      "Progress : 3 of 26 (ta)\n",
      "Progress : 4 of 26 (bd)\n",
      "Progress : 5 of 26 (cc)\n",
      "Progress : 6 of 26 (ci)\n",
      "Progress : 7 of 26 (tc)\n",
      "Progress : 8 of 26 (tq)\n",
      "Progress : 9 of 26 (ec)\n",
      "Progress : 10 of 26 (th)\n",
      "Progress : 11 of 26 (tk)\n",
      "Progress : 12 of 26 (lt)\n",
      "Progress : 13 of 26 (tm)\n",
      "Progress : 14 of 26 (mc)\n",
      "Progress : 15 of 26 (tn)\n",
      "Progress : 16 of 26 (td)\n",
      "Progress : 17 of 26 (tp)\n",
      "Progress : 18 of 26 (sc)\n",
      "Progress : 19 of 26 (ts)\n",
      "Progress : 20 of 26 (su)\n",
      "Progress : 21 of 26 (si)\n",
      "Progress : 22 of 26 (tg)\n",
      "Progress : 23 of 26 (tb)\n",
      "Progress : 24 of 26 (nt)\n",
      "Progress : 25 of 26 (ca)\n",
      "Progress : 26 of 26 (lc)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(journals)) :\n",
    "    resp = requests.post(\"https://csdl-api.computer.org/api/v1/graphql\", \n",
    "                          json={\n",
    "                              \"variables\":{\"idPrefix\":\"%s\"%(journals[i][1])},\n",
    "                              \"query\":'query ($idPrefix : String!) { periodicalIssues(idPrefix : $idPrefix) { label issueNum volume year } }'\n",
    "                          })\n",
    "    body = resp.json()\n",
    "    \n",
    "    #Todo : 저널 별로 year, volume, issueNum 저장\n",
    "    print(\"Progress : %d of %d (%s)\" % (i+1, len(journals), journals[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### articles과 param (idPrefix, year, issueNum)을 통해 article 크롤링"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "query {\n",
    "  articles(idPrefix: \"cc\", year: \"2018\", issueNum: \"02\") {\n",
    "    idPrefix\n",
    "    id\n",
    "    year\n",
    "    pubDate\n",
    "    keywords\n",
    "    title\n",
    "    abstract\n",
    "    authors {\n",
    "      affiliation\n",
    "      fullName\n",
    "      givenName\n",
    "      surname\n",
    "    }\n",
    "    #catalog\n",
    "    #contentType\n",
    "    #pages\n",
    "    #pubType\n",
    "    #sectionTitle\n",
    "    #volume\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.post(\"https://csdl-api.computer.org/api/v1/graphql\", \n",
    "                      json={\n",
    "                          \"variables\":{\"idPrefix\":\"ca\", \"year\":\"2018\", \"issueNum\":\"02\"}, #ci, 2018, 02는 하나의 예시임. 실제로는 idPrefix, year, issueNum 바꿔가며 긁어오기\n",
    "                          \"query\":'query ($idPrefix : String!, $year : String!, $issueNum : String!) { articles(idPrefix: $idPrefix, year: $year, issueNum: $issueNum) { idPrefix id year pubDate keywords title abstract authors { affiliation fullName givenName surname } } }'\n",
    "                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": {\n",
      "        \"articles\": [\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUwwslBG\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Nonvolatile Memory\",\n",
      "                    \"Random Access Memory\",\n",
      "                    \"Encryption\",\n",
      "                    \"Computer Architecture\",\n",
      "                    \"System On Chip\",\n",
      "                    \"Oblivious RAM\",\n",
      "                    \"Non Volatile Memory\",\n",
      "                    \"Memory Security\"\n",
      "                ],\n",
      "                \"title\": \"LEO: Low Overhead Encryption ORAM for Non-Volatile Memories\",\n",
      "                \"abstract\": \"Data confidentiality attacks utilizing memory access patterns threaten exposure of data in modern main memories. Oblivious RAM\\u00a0(ORAM) is an effective cryptographic primitive developed to thwart access-pattern-based attacks in DRAM-based systems. However, in emerging non-volatile memory\\u00a0(NVM) systems, the increased writes due to encryption of multiple data blocks on every Path ORAM (state-of-the-art efficient ORAM) access impose significant energy, lifetime, and performance overheads. LEO\\u00a0(Low overhead E ncryption ORAM)\\u00a0is an efficient Path ORAM encryption architecture that addresses the high write overheads of ORAM integration in NVMs, while providing security equivalent to the baseline Path ORAM. LEO reduces NVM cell writes by securely decreasing the number of block encryptions during the write phase of a Path ORAM access. LEO uses a secure, two-level counter mode encryption framework that opportunistically eliminates re-encryption of unmodified blocks, reducing NVM writes. Our evaluations show that on average, LEO decreases NVM energy by 60 percent, improves lifetime by 1.51 $\\\\times$ , and increases performance by 9 percent over the baseline Path ORAM.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Electrical and Computer Engineering, University of Pittsburgh, Pittsburgh, PA\",\n",
      "                        \"fullName\": \"Joydeep Rakshit\",\n",
      "                        \"givenName\": \"Joydeep\",\n",
      "                        \"surname\": \"Rakshit\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Electrical and Computer Engineering, University of Pittsburgh, Pittsburgh, PA\",\n",
      "                        \"fullName\": \"Kartik Mohanram\",\n",
      "                        \"givenName\": \"Kartik\",\n",
      "                        \"surname\": \"Mohanram\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUzpzeDT\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Hardware\",\n",
      "                    \"Reliability\",\n",
      "                    \"Transient Analysis\",\n",
      "                    \"Multicore Processing\",\n",
      "                    \"Fingerprint Recognition\",\n",
      "                    \"Electrical Engineering\",\n",
      "                    \"Registers\",\n",
      "                    \"Hardware\",\n",
      "                    \"Performance And Reliability\",\n",
      "                    \"Computer System Organization\",\n",
      "                    \"Hardware Transactional Memory\"\n",
      "                ],\n",
      "                \"title\": \"Core Reliability: Leveraging Hardware Transactional Memory\",\n",
      "                \"abstract\": \"Modern microprocessors are more vulnerable to transient faults or soft errors than ever before due to design trends mandating low supply voltage and reduced noise margins, shrinking feature sizes and increased transistor density for fast, low-power circuits. As industry now supports Hardware Transactional Memory (HTM), the features of HTM can be leveraged to add core resiliency to transient errors. In this paper, we propose a novel microarchitecture for transient error detection and recovery based on time redundancy and backward error recovery leveraging HTM's existing features especially its rollback mechanism. We provide implementation details for single-core reliability, minimizing additions to existing HTM supports. We evaluate the performance overheads of the single core with the reliability feature by comparing it to the base machine without the reliability feature. Finally we show how single-core reliability can be extended to multi-core reliability.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Electrical Engineering, University of Southern California, Los Angeles, CA\",\n",
      "                        \"fullName\": \"Sang Wook Stephen Do\",\n",
      "                        \"givenName\": \"Sang Wook Stephen\",\n",
      "                        \"surname\": \"Do\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Electrical Engineering, University of Southern California, Los Angeles, CA\",\n",
      "                        \"fullName\": \"Michel Dubois\",\n",
      "                        \"givenName\": \"Michel\",\n",
      "                        \"surname\": \"Dubois\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUxCitAA\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Predictive Models\",\n",
      "                    \"Hardware\",\n",
      "                    \"Computational Modeling\",\n",
      "                    \"Voltage Measurement\",\n",
      "                    \"Linear Regression\",\n",
      "                    \"Computer Crashes\",\n",
      "                    \"Energy Efficient Computing\",\n",
      "                    \"Design Margins\",\n",
      "                    \"Hardware Reliability\",\n",
      "                    \"Statistical Methods\"\n",
      "                ],\n",
      "                \"title\": \"Statistical Analysis of Multicore CPUs Operation in Scaled Voltage Conditions\",\n",
      "                \"abstract\": \"Designers try to reduce the voltage margins of CPU chips to gain energy without sacrificing reliable operation. Statistical analysis methods are appealing to predict the safe operational margins at the system level as they do not induce area overheads and they can be applied during manufacturing or after the chips\\u2019 release to the market. In this study, we present a comprehensive statistical analysis of the behavior of ARMv8 64-bit cores that are part of the enterprise 8-core X-Gene 2 micro-server family when they operate in scaled voltage conditions. Our prediction schemes that use real hardware counters as input are based on linear regression models with several feature selection techniques that aim to predict the safe voltage margins of any given workload when the cores operate in scaled conditions. Our findings show that our model is able to accurately predict safe voltage margins that provide up to 20.28% power savings.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Computer Architecture Lab, University of Athens, Greece\",\n",
      "                        \"fullName\": \"Manolis Kaliorakis\",\n",
      "                        \"givenName\": \"Manolis\",\n",
      "                        \"surname\": \"Kaliorakis\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Computer Architecture Lab, University of Athens, Greece\",\n",
      "                        \"fullName\": \"Athanasios Chatzidimitriou\",\n",
      "                        \"givenName\": \"Athanasios\",\n",
      "                        \"surname\": \"Chatzidimitriou\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Computer Architecture Lab, University of Athens, Greece\",\n",
      "                        \"fullName\": \"George Papadimitriou\",\n",
      "                        \"givenName\": \"George\",\n",
      "                        \"surname\": \"Papadimitriou\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Computer Architecture Lab, University of Athens, Greece\",\n",
      "                        \"fullName\": \"Dimitris Gizopoulos\",\n",
      "                        \"givenName\": \"Dimitris\",\n",
      "                        \"surname\": \"Gizopoulos\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUwciPho\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Computational Modeling\",\n",
      "                    \"Complexity Theory\",\n",
      "                    \"Two Dimensional Displays\",\n",
      "                    \"Runtime\",\n",
      "                    \"Analytical Models\",\n",
      "                    \"Parallel Processing\",\n",
      "                    \"Computer Architecture\",\n",
      "                    \"Associative Processors\",\n",
      "                    \"Analysis Of Algorithms And Problem Complexity\",\n",
      "                    \"Modeling Techniques\",\n",
      "                    \"Models Of Computation\"\n",
      "                ],\n",
      "                \"title\": \"An Alternative Analytical Approach to Associative Processing\",\n",
      "                \"abstract\": \"Associative Processing (AP) is a promising alternative to the Von Neumann model as it addresses the memory wall problem through its inherent in-memory computations. However, because of the countless design parameter choices, comparisons between implementations of two so radically different models are challenging for simulation-based methods. To tackle these challenges, we develop an alternative analytical approach based on a new concept called architecturally-determined complexity. Using this method, we asymptotically evaluate the runtime/storage/energy bounds of the two models, i.e., AP and Von Neumann. We further apply the method to gain more insights into the performance bottlenecks of traditional AP and develop a new machine model named Two Dimensional AP to address these limitations. Finally, we experimentally validate our analytical method and confirm that the simulation results match our theoretical projections.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Electrical and Computer Engineering, University of Wisconsin - Madison, Madison, WI\",\n",
      "                        \"fullName\": \"Soroosh Khoram\",\n",
      "                        \"givenName\": \"Soroosh\",\n",
      "                        \"surname\": \"Khoram\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Electrical and Computer Engineering, University of Wisconsin - Madison, Madison, WI\",\n",
      "                        \"fullName\": \"Yue Zha\",\n",
      "                        \"givenName\": \"Yue\",\n",
      "                        \"surname\": \"Zha\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Electrical and Computer Engineering, University of Wisconsin - Madison, Madison, WI\",\n",
      "                        \"fullName\": \"Jing Li\",\n",
      "                        \"givenName\": \"Jing\",\n",
      "                        \"surname\": \"Li\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUxAAT9E\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Analog Memory\",\n",
      "                    \"Stochastic Systems\",\n",
      "                    \"Image Processing\",\n",
      "                    \"Image Sensors\",\n",
      "                    \"System Analysis And Design\",\n",
      "                    \"Data Conversion\",\n",
      "                    \"Sensors\",\n",
      "                    \"Stochastic Computing\",\n",
      "                    \"Memory System Design\",\n",
      "                    \"Analog Memory\",\n",
      "                    \"Energy Efficient Design\",\n",
      "                    \"Near Sensor Processing\"\n",
      "                ],\n",
      "                \"title\": \"On Memory System Design for Stochastic Computing\",\n",
      "                \"abstract\": \"Growing uncertainty in design parameters (and therefore, in design functionality) renders stochastic computing particularly promising, which represents and processes data as quantized probabilities. However, due to the difference in data representation, integrating conventional memory (designed and optimized for non-stochastic computing) in stochastic computing systems inevitably incurs a significant data conversion overhead. Barely any stochastic computing proposal to-date covers the memory impact. In this paper, as the first study of its kind to the best of our knowledge, we rethink the memory system design for stochastic computing. The result is a seamless stochastic system, StochMem, which features analog memory to trade the energy and area overhead of data conversion for computation accuracy. In this manner StochMem can reduce the energy (area) overhead by up-to 52.8% (93.7%) at the cost of at most 0.7% loss in computation accuracy.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"University of Minnesota, Minneapolis, MN\",\n",
      "                        \"fullName\": \"S. Karen Khatamifard\",\n",
      "                        \"givenName\": \"S. Karen\",\n",
      "                        \"surname\": \"Khatamifard\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"University of Minnesota, Minneapolis, MN\",\n",
      "                        \"fullName\": \"M. Hassan Najafi\",\n",
      "                        \"givenName\": \"M. Hassan\",\n",
      "                        \"surname\": \"Najafi\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"University of Minnesota, Minneapolis, MN\",\n",
      "                        \"fullName\": \"Ali Ghoreyshi\",\n",
      "                        \"givenName\": \"Ali\",\n",
      "                        \"surname\": \"Ghoreyshi\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"University of Minnesota, Minneapolis, MN\",\n",
      "                        \"fullName\": \"Ulya R. Karpuzcu\",\n",
      "                        \"givenName\": \"Ulya R.\",\n",
      "                        \"surname\": \"Karpuzcu\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"University of Minnesota, Minneapolis, MN\",\n",
      "                        \"fullName\": \"David J. Lilja\",\n",
      "                        \"givenName\": \"David J.\",\n",
      "                        \"surname\": \"Lilja\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUxly97z\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Benchmark Testing\",\n",
      "                    \"Computer Architecture\",\n",
      "                    \"Encryption\",\n",
      "                    \"Cloud Computing\",\n",
      "                    \"Program Processors\",\n",
      "                    \"Benchmarks\",\n",
      "                    \"Data Privacy\",\n",
      "                    \"Encrypted Computation\",\n",
      "                    \"Homomorphic Encryption\",\n",
      "                    \"Leakage Prevention\",\n",
      "                    \"Performance Evaluation\",\n",
      "                    \"Termination Problem\"\n",
      "                ],\n",
      "                \"title\": \"TERMinator Suite: Benchmarking Privacy-Preserving Architectures\",\n",
      "                \"abstract\": \"Security and privacy are fundamental objectives characterizing contemporary cloud computing. Despite the wide adoption of encryption for protecting data in transit and at rest, data in use remains unencrypted inside cloud processors and memories, as computation is not applicable on encrypted values. This limitation introduces security risks, as unencrypted values can be leaked through side-channels or hardware Trojans. To address this problem, encrypted architectures have recently been proposed, which leverage homomorphic encryption to natively process encrypted data using datapaths of thousands of bits. In this case, additional security protections are traded for higher performance penalties, which drives the need for more efficient architectures. In this work, we develop benchmarks specifically tailored to homomorphic computers, to enable comparisons across different architectures. Our benchmark suite, dubbed TERMinator, is unique as it avoids \\u201ctermination problems\\u201d that prohibit making control-flow decisions and evaluating early termination conditions based on encrypted data, as these can leak information. Contrary to generic suites that ignore the fundamental challenges of encrypted computation, our algorithms are tailored to the security primitives of the target encrypted architecture, such as the existence of branching oracles. In our experiments, we compiled our benchmarks for the Cryptoleq architecture and evaluated their performance for a range of security parameters.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"University of Athens, Athens, Greece\",\n",
      "                        \"fullName\": \"Dimitris Mouris\",\n",
      "                        \"givenName\": \"Dimitris\",\n",
      "                        \"surname\": \"Mouris\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"New York University, New York, NY\",\n",
      "                        \"fullName\": \"Nektarios Georgios Tsoutsos\",\n",
      "                        \"givenName\": \"Nektarios Georgios\",\n",
      "                        \"surname\": \"Tsoutsos\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"New York University, New York, NY\",\n",
      "                        \"fullName\": \"Michail Maniatakos\",\n",
      "                        \"givenName\": \"Michail\",\n",
      "                        \"surname\": \"Maniatakos\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUyft7wJ\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Benchmark Testing\",\n",
      "                    \"Measurement\",\n",
      "                    \"Correlation\",\n",
      "                    \"Linux\",\n",
      "                    \"Memory Management\",\n",
      "                    \"Hardware\",\n",
      "                    \"Computational Modeling\",\n",
      "                    \"Compression\",\n",
      "                    \"Memory\",\n",
      "                    \"DRAM\",\n",
      "                    \"Evaluation\",\n",
      "                    \"Methodology\",\n",
      "                    \"Representative Regions\",\n",
      "                    \"Compressed Memory\",\n",
      "                    \"Translation\",\n",
      "                    \"Multi Core\",\n",
      "                    \"Workloads\"\n",
      "                ],\n",
      "                \"title\": \"CompressPoints: An Evaluation Methodology for Compressed Memory Systems\",\n",
      "                \"abstract\": \"Current memory technology has hit a wall trying to scale to meet the increasing demands of modern client and datacenter systems. Data compression is a promising solution to this problem. Several compressed memory systems have been proposed in the past years\\u00a0[1] , [2] , [3] , [4] . Unfortunately, a reasonable methodology to evaluate these systems is missing. In this paper, we identify the challenges for evaluating main memory compression. We propose an effective methodology to evaluate a compressed memory system by proposing mechanisms to: (i) incorporate correct virtual address translation, (ii) choose a region in the application that is representative of the compression ratio, in addition to regular metrics like IPC and cache hit rates, and (iii) choose a representative region for multi-core workloads, bringing down the correlation error from 12.8 to 3.8 percent.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"University of Texas at Austin, Austin, TX\",\n",
      "                        \"fullName\": \"Esha Choukse\",\n",
      "                        \"givenName\": \"Esha\",\n",
      "                        \"surname\": \"Choukse\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"University of Texas at Austin, Austin, TX\",\n",
      "                        \"fullName\": \"Mattan Erez\",\n",
      "                        \"givenName\": \"Mattan\",\n",
      "                        \"surname\": \"Erez\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Intel Labs, Santa Clara, CA\",\n",
      "                        \"fullName\": \"Alaa Alameldeen\",\n",
      "                        \"givenName\": \"Alaa\",\n",
      "                        \"surname\": \"Alameldeen\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUx0ge7W\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Random Access Memory\",\n",
      "                    \"Microprocessors\",\n",
      "                    \"Power Demand\",\n",
      "                    \"Memory Management\",\n",
      "                    \"Transforms\",\n",
      "                    \"Benchmark Testing\",\n",
      "                    \"DRAM Refresh\",\n",
      "                    \"Value Transformation\",\n",
      "                    \"DRAM Energy\"\n",
      "                ],\n",
      "                \"title\": \"Zebra Refresh: Value Transformation for Zero-Aware DRAM Refresh Reduction\",\n",
      "                \"abstract\": \"Refresh operations consume growing portions of DRAM power with increasing DRAM capacity. To reduce the power consumption of such refresh operations, this paper proposes a novel value-aware refresh reduction technique exploiting the abundance of zero values in the memory contents. The proposed Zebra refresh architecture transforms the value and mapping of DRAM data to increase consecutive zero values, and skips a refresh operation for a row containing zero values entirely. Zebra converts memory blocks to base and delta values, inspired by a prior compression technique. Once values are converted, bits are transposed to place consecutive zeros matching the refresh granularity. The experimental results show Zebra refresh can reduce DRAM refresh operations by 43 percent on average for a set of benchmark applications.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"School of Computing, KAIST, Daejeon, Republic of Korea\",\n",
      "                        \"fullName\": \"Seikwon Kim\",\n",
      "                        \"givenName\": \"Seikwon\",\n",
      "                        \"surname\": \"Kim\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"School of Computing, KAIST, Daejeon, Republic of Korea\",\n",
      "                        \"fullName\": \"Wonsang Kwak\",\n",
      "                        \"givenName\": \"Wonsang\",\n",
      "                        \"surname\": \"Kwak\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"School of Computing, KAIST, Daejeon, Republic of Korea\",\n",
      "                        \"fullName\": \"Changdae Kim\",\n",
      "                        \"givenName\": \"Changdae\",\n",
      "                        \"surname\": \"Kim\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"School of Computing, KAIST, Daejeon, Republic of Korea\",\n",
      "                        \"fullName\": \"Jaehyuk Huh\",\n",
      "                        \"givenName\": \"Jaehyuk\",\n",
      "                        \"surname\": \"Huh\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUzpzeEL\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Bandwidth\",\n",
      "                    \"Machine Learning\",\n",
      "                    \"Performance Evaluation\",\n",
      "                    \"Virtualization\",\n",
      "                    \"Graphics Processing Units\",\n",
      "                    \"Systems Architecture\",\n",
      "                    \"Training\",\n",
      "                    \"Computer Architecture\",\n",
      "                    \"System Architecture\",\n",
      "                    \"Hardware Acceleration\",\n",
      "                    \"Neural Network\",\n",
      "                    \"Deep Learning\"\n",
      "                ],\n",
      "                \"title\": \"A Case for Memory-Centric HPC System Architecture for Training Deep Neural Networks\",\n",
      "                \"abstract\": \"As the models and the datasets to train deep learning (DL) models scale, system architects are faced with new challenges, one of which is the memory capacity bottleneck, where the limited physical memory inside the accelerator device constrains the algorithm that can be studied. We propose a memory-centric deep learning system that can transparently expand the memory capacity accessible to the accelerators while also providing fast inter-device communication for parallel training. Our proposal aggregates a pool of memory modules locally within the device-side interconnect, which are decoupled from the host interface and function as a vehicle for transparent memory capacity expansion. Compared to conventional systems, our proposal achieves an average  $2.1\\\\times$  speedup on eight DL applications and increases the system-wide memory capacity to tens of TBs.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Pohang University of Science and Technology, Pohang, Gyeongsangbuk-do, South Korea\",\n",
      "                        \"fullName\": \"Youngeun Kwon\",\n",
      "                        \"givenName\": \"Youngeun\",\n",
      "                        \"surname\": \"Kwon\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Pohang University of Science and Technology, Pohang, Gyeongsangbuk-do, South Korea\",\n",
      "                        \"fullName\": \"Minsoo Rhu\",\n",
      "                        \"givenName\": \"Minsoo\",\n",
      "                        \"surname\": \"Rhu\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUwbs1Ur\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Load Management\",\n",
      "                    \"Random Access Memory\",\n",
      "                    \"Throughput\",\n",
      "                    \"Computer Architecture\",\n",
      "                    \"Switches\",\n",
      "                    \"Transistors\",\n",
      "                    \"Microprocessors\",\n",
      "                    \"STT MRAM\",\n",
      "                    \"Memory Systems\",\n",
      "                    \"Non Volatile Memories\"\n",
      "                ],\n",
      "                \"title\": \"Bit-Level Load Balancing: A New Technique for Improving the Write Throughput of Deeply Scaled STT-MRAM\",\n",
      "                \"abstract\": \"Emerging non-volatile memories (NVMs) have drawn significant attention as potential DRAM replacements. STT-MRAM is one of the most promising NVMs due to its relatively low write energy, high speed, and high endurance. However, STT-MRAM suffers from its own scaling problems. As the size of the access transistor is decreased to reduce the cell area, the magnitude of the switching current that is supplied to the storage element decreases. The reduced switching current significantly lengthens the switching time, which makes write throughput a significant performance bottleneck for a memory system constructed from dense STT-MRAM cells. We introduce bit-level load balancing, a new technique that mitigates the performance overhead of limited write throughput in high-density, STT-MRAM based main memories. Bit-level load balancing takes advantage of the observation that many of the bits within a row of STT-MRAM remain unchanged when performing a write. The key idea is to architect the memory system such that different columns of different rows can be simultaneously written to an STT-MRAM subarray. By interleaving in time the bit updates from multiple writes, bit level load balancing improves average system performance by 19 percent, and comes within 6 percent of the performance of a DRAM based system.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Computer Science and Department of Electrical & Computer Engineering, CSB Room 422, University of Rochester, Rochester, NY\",\n",
      "                        \"fullName\": \"Engin Ipek\",\n",
      "                        \"givenName\": \"Engin\",\n",
      "                        \"surname\": \"Ipek\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Huawei Technologies Co. Ltd., Shenzhen, Guangdong, China\",\n",
      "                        \"fullName\": \"Florian Longnos\",\n",
      "                        \"givenName\": \"Florian\",\n",
      "                        \"surname\": \"Longnos\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Huawei Technologies Co. Ltd., Shenzhen, Guangdong, China\",\n",
      "                        \"fullName\": \"Shihai Xiao\",\n",
      "                        \"givenName\": \"Shihai\",\n",
      "                        \"surname\": \"Xiao\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Huawei Technologies Co. Ltd., Shenzhen, Guangdong, China\",\n",
      "                        \"fullName\": \"Wei Yang\",\n",
      "                        \"givenName\": \"Wei\",\n",
      "                        \"surname\": \"Yang\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUILLkIj\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Task Analysis\",\n",
      "                    \"Instruction Sets\",\n",
      "                    \"Computer Architecture\",\n",
      "                    \"Libraries\",\n",
      "                    \"Parallel Processing\",\n",
      "                    \"Runtime\",\n",
      "                    \"Containers\",\n",
      "                    \"Map Reduce\",\n",
      "                    \"Runtime Systems\",\n",
      "                    \"Multi Cores\"\n",
      "                ],\n",
      "                \"title\": \"Decoupled MapReduce for Shared-Memory Multi-Core Architectures\",\n",
      "                \"abstract\": \"Modern multi-core processors exhibit high integration densities, e.g., up to several tens of cores. Multiple programming frameworks have emerged to facilitate the development of highly parallel applications. The MapReduce programming model, after having demonstrated its usability in the area of distributed computing systems, has been adapted to the needs of shared-memory multi-processors showing promising results in comparison with conventional multi-threaded libraries, e.g., pthreads. In this paper we enhance the traditional MapReduce architecture by decoupling the map and combine phases in order to boost parallel execution. We show that combiners\\u2019 memory intensive features limit the system\\u2019s degree of parallelism, thus resulting in sub-optimal hardware utilization, leaving space for further performance improvements. The proposed decoupled MapReduce architecture is evaluated into a NUMA server platform, showing that the adoption of the De-MapR runtime enables more efficient hardware utilization and competent run-time improvements. We demonstrate that the proposed solution achieves execution speedups of up to 2.46x compared to a state-of-the-art, shared-memory MapReduce library.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"National Technical University of Athens, Zografou, Greece\",\n",
      "                        \"fullName\": \"Konstantinos Iliakis\",\n",
      "                        \"givenName\": \"Konstantinos\",\n",
      "                        \"surname\": \"Iliakis\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"National Technical University of Athens, Zografou, Greece\",\n",
      "                        \"fullName\": \"Sotirios Xydis\",\n",
      "                        \"givenName\": \"Sotirios\",\n",
      "                        \"surname\": \"Xydis\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"National Technical University of Athens, Zografou, Greece\",\n",
      "                        \"fullName\": \"Dimitrios Soudris\",\n",
      "                        \"givenName\": \"Dimitrios\",\n",
      "                        \"surname\": \"Soudris\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUIIVleu\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Field Programmable Gate Arrays\",\n",
      "                    \"Synchronization\",\n",
      "                    \"Instruction Sets\",\n",
      "                    \"Data Structures\",\n",
      "                    \"Programming\",\n",
      "                    \"Semantics\",\n",
      "                    \"Throughput\",\n",
      "                    \"Reconfigurable Hardware\",\n",
      "                    \"Data Structures\",\n",
      "                    \"Heterogeneous Systems\"\n",
      "                ],\n",
      "                \"title\": \"Breaking the Synchronization Bottleneck with Reconfigurable Transactional Execution\",\n",
      "                \"abstract\": \"The advent of FPGA-based hybrid architecture offers the opportunity of customizing memory subsystems to enhance the overall system performance. However, it is not straightforward to design efficient FPGA circuits for emerging FPGAs applications such as in-memory database and graph analytics, which heavily depend on concurrent data structures (CDS\\u2019). Highly dynamic behaviors of CDS\\u2019 have to be orchestrated by synchronization primitives for correct execution. These primitives induce overwhelming memory traffic for synchronizations on FPGAs. This paper proposes a novel method for systematically exploring and exploiting memory-level parallelism (MLP) of CDS by transactional execution on FPGAs. Inspired by the idea that semantics of transactions can be implemented in a more efficient and scalable manner on FPGAs than on CPUs, we propose a transaction-based reconfigurable runtime system for capturing MLP of CDS\\u2019. Experiments on linked-list and skip-list show our approach achieves 5.18x and 1.55x throughput improvement on average than lock-based FPGA implementations and optimized CDS algorithms on a state-of-the-art multi-core CPU respectively.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China\",\n",
      "                        \"fullName\": \"Zhaoshi Li\",\n",
      "                        \"givenName\": \"Zhaoshi\",\n",
      "                        \"surname\": \"Li\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China\",\n",
      "                        \"fullName\": \"Leibo Liu\",\n",
      "                        \"givenName\": \"Leibo\",\n",
      "                        \"surname\": \"Liu\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China\",\n",
      "                        \"fullName\": \"Yangdong Deng\",\n",
      "                        \"givenName\": \"Yangdong\",\n",
      "                        \"surname\": \"Deng\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China\",\n",
      "                        \"fullName\": \"Shouyi Yin\",\n",
      "                        \"givenName\": \"Shouyi\",\n",
      "                        \"surname\": \"Yin\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China\",\n",
      "                        \"fullName\": \"Shaojun Wei\",\n",
      "                        \"givenName\": \"Shaojun\",\n",
      "                        \"surname\": \"Wei\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUwhpBSd\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Computer Architecture\",\n",
      "                    \"Microprocessors\",\n",
      "                    \"Random Access Memory\",\n",
      "                    \"Throughput\",\n",
      "                    \"Switches\",\n",
      "                    \"Decoding\",\n",
      "                    \"Writing\",\n",
      "                    \"Memory Systems\",\n",
      "                    \"Non Volatile Memories\",\n",
      "                    \"STT MRAM\"\n",
      "                ],\n",
      "                \"title\": \"Vertical Writes: Closing the Throughput Gap between Deeply Scaled STT-MRAM and DRAM\",\n",
      "                \"abstract\": \"STT-MRAM is a second generation MRAM technology that addresses many of the scaling problems of earlier generation magnetic RAMs, and is a promising candidate to replace DRAM due to its high operational speed, scalable energy characteristics, and high write endurance. However, making the density of STT-MRAM competitive with that of DRAM while maintaining DRAM-like write throughput has proven challenging. Reducing the area of an STT-MRAM cell requires decreasing the width of the cell access transistor, which lowers the magnitude of the switching current supplied to the storage element during writes, and significantly hampers the switching speed. Consequently, write throughput constitutes a fundamental performance bottleneck for memory systems built from deeply scaled, dense STT-MRAM cells. This paper introduces vertical writes, a new technique that improves the write throughput of memory systems built from high-density STT-MRAM. Vertical writes exploit the observation that once the switching voltage has been applied across the bitlines and and sourcelines in an STT-MRAM array, it is possible to initiate the write operation for additional cells that are attached to the same column by simply turning on the corresponding wordlines. By leveraging the ability to write a 0 or a 1 to multiple cells at once, vertical writes improve average system performance by 21 percent, and enable an STT-MRAM based system to come within 5 percent of the performance of a DRAM based system.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"University of Rochester, Rochester, New York\",\n",
      "                        \"fullName\": \"Engin Ipek\",\n",
      "                        \"givenName\": \"Engin\",\n",
      "                        \"surname\": \"Ipek\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Huawei Technologies Co Ltd, Shenzhen, Guangdong, China\",\n",
      "                        \"fullName\": \"Florian Longnos\",\n",
      "                        \"givenName\": \"Florian\",\n",
      "                        \"surname\": \"Longnos\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Huawei Technologies Co Ltd, Shenzhen, Guangdong, China\",\n",
      "                        \"fullName\": \"Shihai Xiao\",\n",
      "                        \"givenName\": \"Shihai\",\n",
      "                        \"surname\": \"Xiao\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Huawei Technologies Co Ltd, Shenzhen, Guangdong, China\",\n",
      "                        \"fullName\": \"Wei Yang\",\n",
      "                        \"givenName\": \"Wei\",\n",
      "                        \"surname\": \"Yang\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUwInv6s\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Motion Pictures\",\n",
      "                    \"Servers\",\n",
      "                    \"Electric Breakdown\",\n",
      "                    \"Videos\",\n",
      "                    \"Quality Of Service\",\n",
      "                    \"Open Source Software\",\n",
      "                    \"Scalability\",\n",
      "                    \"Super Very Large Computers\",\n",
      "                    \"Distributed Applications\",\n",
      "                    \"Application Studies Resulting In Better Multiple Processor Systems\"\n",
      "                ],\n",
      "                \"title\": \"The Architectural Implications of Cloud Microservices\",\n",
      "                \"abstract\": \"Cloud services have recently undergone a shift from monolithic applications to microservices, with hundreds or thousands of loosely-coupled microservices comprising the end-to-end application. Microservices present both opportunities and challenges when optimizing for quality of service (QoS) and cloud utilization. In this paper we explore the implications cloud microservices have on system bottlenecks, and datacenter server design. We first present and characterize an end-to-end application built using tens of popular open-source microservices that implements a movie renting and streaming service, and is modular and extensible. We then use the end-to-end service to study the scalability and performance bottlenecks of microservices, and highlight implications they have on the design of datacenter hardware. Specifically, we revisit the long-standing debate of brawny versus wimpy cores in the context of microservices, we quantify the I-cache pressure they introduce, and measure the time spent in computation versus communication between microservices over RPCs. As more cloud applications switch to this new programming model, it is increasingly important to revisit the assumptions we have previously used to build and manage cloud systems.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Cornell University, Ithaca, NY\",\n",
      "                        \"fullName\": \"Yu Gan\",\n",
      "                        \"givenName\": \"Yu\",\n",
      "                        \"surname\": \"Gan\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Cornell University, Ithaca, NY\",\n",
      "                        \"fullName\": \"Christina Delimitrou\",\n",
      "                        \"givenName\": \"Christina\",\n",
      "                        \"surname\": \"Delimitrou\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUytWFbf\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Data Transfer\",\n",
      "                    \"Coherence\",\n",
      "                    \"Memory Management\",\n",
      "                    \"Encryption\",\n",
      "                    \"Engines\",\n",
      "                    \"Metadata\",\n",
      "                    \"Distributed Databases\",\n",
      "                    \"Distributed Computing\",\n",
      "                    \"Computer Security\",\n",
      "                    \"Shared Memory\",\n",
      "                    \"Integrity Tree\"\n",
      "                ],\n",
      "                \"title\": \"Distributed Memory Integrity Trees\",\n",
      "                \"abstract\": \"Ensuring the correct execution of a program running on untrusted computing platforms, wherein the OS, hypervisor, and all off-CPU-chip hardware, including memory, are untrusted, (also) requires protecting the integrity of the memory content against replay attacks. This requires dedicated tracking structures and in-chip state storage. For this purpose, integrity trees are used in various forms, varying in complexity, size, and performance; yet, existing integrity trees do not address distributed, shared-memory computations, for which one must also ensure the integrity of the coherence state of the memory. Observing that a block not residing at a given node merely needs to be known by that node as such, we present the novel Distributed Integrity Tree (DIT) method, and show that it can be used effectively to extend existing integrity trees to parallel and distributed environments. Using DIT, we constructed a Distributed Merkle Tree, a Distributed Bonsai Merkle Tree, and a distributed Intel SGX's Memory Encryption Engine integrity mechanism. All these extensions entail negligible overhead.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Electrical Engineering Department, Technion, Haifa, Israel\",\n",
      "                        \"fullName\": \"Ofir Shwartz\",\n",
      "                        \"givenName\": \"Ofir\",\n",
      "                        \"surname\": \"Shwartz\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Electrical Engineering Department, Technion, Haifa, Israel\",\n",
      "                        \"fullName\": \"Yitzhak Birk\",\n",
      "                        \"givenName\": \"Yitzhak\",\n",
      "                        \"surname\": \"Birk\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUxlgy5K\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Prefetching\",\n",
      "                    \"Random Access Memory\",\n",
      "                    \"Memory Management\",\n",
      "                    \"Phase Change Materials\",\n",
      "                    \"Load Modeling\",\n",
      "                    \"Engines\",\n",
      "                    \"Training Data\",\n",
      "                    \"Prefetching\",\n",
      "                    \"Main Memory\",\n",
      "                    \"Buffer Management\",\n",
      "                    \"Machine Learning\"\n",
      "                ],\n",
      "                \"title\": \"Regression Prefetcher with Preprocessing for DRAM-PCM Hybrid Main Memory\",\n",
      "                \"abstract\": \"This research is to design an effective hybrid main memory structure for graph processing applications, because it is quite expensive to use only high-speed DRAM for such applications. Thus, we propose a DRAM-PCM hybrid main memory structure to reduce the cost and energy consumption and design regression prefetch scheme to cope with irregular access patterns in large graph processing workloads. In addition, the prefetch includes preprocessing algorithm to maximize prefetching performance. Our experimental evaluation shows a performance improvement of 36 percent over a conventional DRAM model, 15 percent over existing prefetch models such as GHB/PC, SMS, and AMPM, and 6 percent over the latest model.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Computer Science, Yonsei University, Seoul, Korea\",\n",
      "                        \"fullName\": \"Ji-Tae Yun\",\n",
      "                        \"givenName\": \"Ji-Tae\",\n",
      "                        \"surname\": \"Yun\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Computer Science, Yonsei University, Seoul, Korea\",\n",
      "                        \"fullName\": \"Su-Kyung Yoon\",\n",
      "                        \"givenName\": \"Su-Kyung\",\n",
      "                        \"surname\": \"Yoon\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Computer Science, Yonsei University, Seoul, Korea\",\n",
      "                        \"fullName\": \"Jeong-Geun Kim\",\n",
      "                        \"givenName\": \"Jeong-Geun\",\n",
      "                        \"surname\": \"Kim\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Computer Science, Yonsei University, Seoul, Korea\",\n",
      "                        \"fullName\": \"Bernd Burgstaller\",\n",
      "                        \"givenName\": \"Bernd\",\n",
      "                        \"surname\": \"Burgstaller\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Computer Science, Yonsei University, Seoul, Korea\",\n",
      "                        \"fullName\": \"Shin-Dug Kim\",\n",
      "                        \"givenName\": \"Shin-Dug\",\n",
      "                        \"surname\": \"Kim\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUxly97A\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Error Correction\",\n",
      "                    \"Phase Change Materials\",\n",
      "                    \"Computer Architecture\",\n",
      "                    \"Error Correction Codes\",\n",
      "                    \"Aging\",\n",
      "                    \"Registers\",\n",
      "                    \"Random Access Memory\",\n",
      "                    \"Emerging Memories\",\n",
      "                    \"Reliability\",\n",
      "                    \"Wear Leveling\",\n",
      "                    \"And Fault Tolerance\"\n",
      "                ],\n",
      "                \"title\": \"RETROFIT: Fault-Aware Wear Leveling\",\n",
      "                \"abstract\": \"Phase-change memory (PCM) and resistive memory (RRAM) are promising alternatives to traditional memory technologies. However, both PCM and RRAM suffer from limited write endurance and due to process variation from scaling, increasing number of early cell failures continue to put pressure on wear-leveling and fault tolerance techniques. In this paper, we propose RETROFIT, which leverages the spare \\u201cgap\\u201d row used as temporary storage in wear leveling to also be used strategically to guard against early cell wear out. RETROFIT is compatible with error correction schemes targeted at mitigating stuck-at faults and provides benefits when single or multiple spare rows are available. RETROFIT enhances lifetime by as much as 107 percent over traditional gap-based wear leveling and 8 percent over perfectly uniform wear leveling with a similar overhead. Furthermore, RETROFIT scales better than wear-leveling combined with error correction as process variation increases.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"National University of Defense Technology, Changsha, China\",\n",
      "                        \"fullName\": \"Jiangwei Zhang\",\n",
      "                        \"givenName\": \"Jiangwei\",\n",
      "                        \"surname\": \"Zhang\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"ECE Department, University of Pittsburgh, Pittsburgh, PA\",\n",
      "                        \"fullName\": \"Donald Kline\",\n",
      "                        \"givenName\": \"Donald\",\n",
      "                        \"surname\": \"Kline\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"National University of Defense Technology, Changsha, China\",\n",
      "                        \"fullName\": \"Liang Fang\",\n",
      "                        \"givenName\": \"Liang\",\n",
      "                        \"surname\": \"Fang\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"CS Department, University of Pittsburgh, Pittsburgh, PA\",\n",
      "                        \"fullName\": \"Rami Melhem\",\n",
      "                        \"givenName\": \"Rami\",\n",
      "                        \"surname\": \"Melhem\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"ECE Department, University of Pittsburgh, Pittsburgh, PA\",\n",
      "                        \"fullName\": \"Alex K. Jones\",\n",
      "                        \"givenName\": \"Alex K.\",\n",
      "                        \"surname\": \"Jones\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUy0ZzUs\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Quality Of Service\",\n",
      "                    \"Runtime\",\n",
      "                    \"Approximate Computing\",\n",
      "                    \"Monitoring\",\n",
      "                    \"Cloud Computing\",\n",
      "                    \"Interference\",\n",
      "                    \"Switches\",\n",
      "                    \"Super Very Large Computers\",\n",
      "                    \"Scheduling And Task Partitioning\",\n",
      "                    \"Support For Dynamic Compilation\"\n",
      "                ],\n",
      "                \"title\": \"Leveraging Approximation to Improve Datacenter Resource Efficiency\",\n",
      "                \"abstract\": \"Cloud multi-tenancy is typically constrained to a single interactive service colocated with one or more batch, low-priority services, whose performance can be sacrificed. Approximate computing applications offer the opportunity to enable tighter colocation among multiple applications whose performance is important. We present Pliant, a lightweight cloud runtime that leverages the ability of approximate computing applications to tolerate some loss in output quality to boost the utilization of shared servers. During periods of high contention, Pliant employs incremental and interference-aware approximation to reduce interference in shared resources. We evaluate Pliant across different approximate applications, and show that it preserves QoS for all co-scheduled workloads, while incurring at most a 5 percent loss in output quality.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Cornell University, Ithaca, NY, USA\",\n",
      "                        \"fullName\": \"Neeraj Kulkarni\",\n",
      "                        \"givenName\": \"Neeraj\",\n",
      "                        \"surname\": \"Kulkarni\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Cornell University, Ithaca, NY, USA\",\n",
      "                        \"fullName\": \"Feng Qi\",\n",
      "                        \"givenName\": \"Feng\",\n",
      "                        \"surname\": \"Qi\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Cornell University, Ithaca, NY, USA\",\n",
      "                        \"fullName\": \"Christina Delimitrou\",\n",
      "                        \"givenName\": \"Christina\",\n",
      "                        \"surname\": \"Delimitrou\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUxjyXcn\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Prefetching\",\n",
      "                    \"Synchronization\",\n",
      "                    \"Registers\",\n",
      "                    \"Pipelines\",\n",
      "                    \"Hardware\",\n",
      "                    \"Chip Multiprocessor\",\n",
      "                    \"Hardware Prefetching\",\n",
      "                    \"Multi Threading\",\n",
      "                    \"Shared Memory\"\n",
      "                ],\n",
      "                \"title\": \"MTB-Fetch: Multithreading Aware Hardware Prefetching for Chip Multiprocessors\",\n",
      "                \"abstract\": \"To fully exploit the scaling performance in Chip Multiprocessors, applications must be divided into semi-independent processes that can run concurrently on multiple cores within a system. One major class of such applications, shared-memory, multi-threaded applications, requires programmers insert thread synchronization primitives (i.e., locks, barriers, and condition variables) in their critical sections to synchronize data access between processes. For this class of applications, scaling performance requires balanced per-thread workloads with little time spent in critical sections. In practice, however, threads often waste significant time waiting to acquire locks/barriers in their critical sections, leading to thread imbalance and poor performance scaling. Moreover, critical sections often stall data prefetchers that mitigate the effects of long critical section stalls by ensuring data is preloaded in the core caches when the critical section is complete. In this paper we examine a pure hardware technique to enable safe data prefetching beyond synchronization points in CMPs. We show that successful prefetching beyond synchronization points requires overcoming two significant challenges in existing prefetching techniques. First, we find that typical data prefetchers are designed to trigger prefetches based on current misses. This approach this works well for traditional, continuously executing, single-threaded applications. However, when a thread stalls on a synchronization point, it typically does not produce any new memory references to trigger a prefetcher. Second, even in the event that a prefetch were to be correctly directed to read beyond a synchronization point, it will likely prefetch shared data from another core before this data has been written. While this prefetch would be considered \\u201caccurate\\u201d it is highly undesirable, because such a prefetch would lead to three extra \\u201cping-pong\\u201d movements back and forth between private caches in the producing and consuming cores, incurring more latency and energy overhead than without prefetching. We develop a new data prefetcher, Multi-Thread B-Fetch (MTB-Fetch), built as an extension to a previous single-threaded data prefetcher. MTB-Fetch addresses both issues in prefetching for shared memory multi-threaded workloads. MTB-Fetch achieves a speedup of 9.3 percent for multi-threaded applications with little additional hardware.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Electrical and Computer Engineering, Texas A&M University, College Station, TX, USA\",\n",
      "                        \"fullName\": \"Laith M. AlBarakat\",\n",
      "                        \"givenName\": \"Laith M.\",\n",
      "                        \"surname\": \"AlBarakat\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Electrical and Computer Engineering, Texas A&M University, College Station, TX, USA\",\n",
      "                        \"fullName\": \"Paul V. Gratz\",\n",
      "                        \"givenName\": \"Paul V.\",\n",
      "                        \"surname\": \"Gratz\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Computer Science and Engineering, Texas A&M University, College Station, TX, USA\",\n",
      "                        \"fullName\": \"Daniel A. Jimenez\",\n",
      "                        \"givenName\": \"Daniel A.\",\n",
      "                        \"surname\": \"Jimenez\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUxBJhxm\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Engines\",\n",
      "                    \"Hardware\",\n",
      "                    \"Rockets\",\n",
      "                    \"Pipelines\",\n",
      "                    \"Sequential Analysis\",\n",
      "                    \"Program Processors\",\n",
      "                    \"Heterogeneous Hybrid Systems\",\n",
      "                    \"Parallel Architectures\",\n",
      "                    \"Bioinformatics Genome Or Protein Databases\"\n",
      "                ],\n",
      "                \"title\": \"MPU-BWM: Accelerating Sequence Alignment\",\n",
      "                \"abstract\": \"DNA sequencing and assembly spans life-altering applications like disease diagnosis to answering questions about our ancestory. Sequencing involves state-of-the-art machines generating nucleic acid sequences (AGCT) from wet samples like blood or salvia, followed by aligning these sequences against known reference sequences. Due to the rapid advancement in sequence generation machines relative to Moore's law, the second step (alignment) has now become the bottleneck. Today's state-of-the-art technology for alignment runs software like BWA-MEM on a cluster of high performance general purpose machines that cannot keep up with the rapid rate of data generated by each new generation of sequencer machines. Recent proposals from academia that claim orders of magnitude alignment speedup come at a cost of significant disruption to the hardware and software currently in use in the industry. In this work, we propose MPU-BWM, a hardware-software solution that achieves orders of magnitude speedup (57 $\\\\times$  over single core x86) on the state-of-the-art BWA-MEM algorithm, with non-intrusive integration to existing processing clusters and with minimal modifications to the BWA-MEM software.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"SimpleMachines, Inc., Madison, WI, USA\",\n",
      "                        \"fullName\": \"Thiruvengadam Vijayaraghavan\",\n",
      "                        \"givenName\": \"Thiruvengadam\",\n",
      "                        \"surname\": \"Vijayaraghavan\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"James Madison Memorial High School, Madison, WI, USA\",\n",
      "                        \"fullName\": \"Amit Rajesh\",\n",
      "                        \"givenName\": \"Amit\",\n",
      "                        \"surname\": \"Rajesh\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"SimpleMachines, Inc., Madison, WI, USA\",\n",
      "                        \"fullName\": \"Karthikeyan Sankaralingam\",\n",
      "                        \"givenName\": \"Karthikeyan\",\n",
      "                        \"surname\": \"Sankaralingam\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUxBrGjJ\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Instruction Sets\",\n",
      "                    \"Synchronization\",\n",
      "                    \"Multicore Processing\",\n",
      "                    \"Predictive Models\",\n",
      "                    \"Microarchitecture\",\n",
      "                    \"Computational Modeling\",\n",
      "                    \"Mathematical Model\",\n",
      "                    \"Modeling\",\n",
      "                    \"Micro Architecture\",\n",
      "                    \"Performance\",\n",
      "                    \"Multi Threaded\"\n",
      "                ],\n",
      "                \"title\": \"RPPM: Rapid Performance Prediction of Multithreaded Applications on Multicore Hardware\",\n",
      "                \"abstract\": \"This paper proposes RPPM which, based on a microarchitecture-independent profile of a multithreaded application, predicts its performance on a previously unseen multicore platform. RPPM breaks up multithreaded program execution into epochs based on synchronization primitives, and then predicts per-epoch active execution times for each thread and synchronization overhead to arrive at a prediction for overall application performance. RPPM predicts performance within 12 percent on average (27 percent max error) compared to cycle-level simulation. We present a case study to illustrate that RPPM can be used for making accurate multicore design trade-offs early in the design cycle.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Ghent University, Gent, Belgium\",\n",
      "                        \"fullName\": \"Sander De Pestel\",\n",
      "                        \"givenName\": \"Sander\",\n",
      "                        \"surname\": \"De Pestel\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Ghent University, Gent, Belgium\",\n",
      "                        \"fullName\": \"Sam Van den Steen\",\n",
      "                        \"givenName\": \"Sam Van den\",\n",
      "                        \"surname\": \"Steen\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Ghent University, Gent, Belgium\",\n",
      "                        \"fullName\": \"Shoaib Akram\",\n",
      "                        \"givenName\": \"Shoaib\",\n",
      "                        \"surname\": \"Akram\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Ghent University, Gent, Belgium\",\n",
      "                        \"fullName\": \"Lieven Eeckhout\",\n",
      "                        \"givenName\": \"Lieven\",\n",
      "                        \"surname\": \"Eeckhout\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13rRUy0ZzUt\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Kernel\",\n",
      "                    \"Graphics Processing Units\",\n",
      "                    \"Bandwidth\",\n",
      "                    \"Hardware\",\n",
      "                    \"Interference\",\n",
      "                    \"Resource Management\",\n",
      "                    \"Training\",\n",
      "                    \"Slowdown Prediction\",\n",
      "                    \"Scalability\",\n",
      "                    \"Interference\",\n",
      "                    \"Spatial Multitasking GPGP Us\"\n",
      "                ],\n",
      "                \"title\": \"KSM: Online Application-Level Performance Slowdown Prediction for Spatial Multitasking GPGPU\",\n",
      "                \"abstract\": \"Colocating multiple applications on the same spatial multitasking GPGPU improves the system-wide throughput. However, the colocated applications are slowed down differently due to the contention on streaming multiprocessors (SMs), L2 cache and global memory bandwidth. The ability to precisely predict application slowdowns online is useful in many scenarios, e.g., ensuring fair pricing in multi-tenant Cloud systems. Prior work on predicting application slowdown is either inaccurate, due to the ignoring of contention on SMs, or inefficient, due to the expensive sequential profiling of concurrent applications via runtime environment switching. To solve the above problem, we propose KSM that enables precise and efficient application-level slowdown prediction without priori application knowledge. KSM is proposed based on the observation that hardware event statistics caused by the colocated applications are strongly correlated with their slowdowns. In more detail, KSM builds a slowdown model based on the hardware event statistics using machine learning techniques offline. At runtime, KSM collects the hardware event statistics, and predicts the slowdowns of all the colocated applications based on the model. Our experimental results show that KSM has negligible runtime overhead and precisely predicts the application-level slowdowns with the prediction error smaller than 9.7 percent.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, P. R. China\",\n",
      "                        \"fullName\": \"Wenyi Zhao\",\n",
      "                        \"givenName\": \"Wenyi\",\n",
      "                        \"surname\": \"Zhao\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, P. R. China\",\n",
      "                        \"fullName\": \"Quan Chen\",\n",
      "                        \"givenName\": \"Quan\",\n",
      "                        \"surname\": \"Chen\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, P. R. China\",\n",
      "                        \"fullName\": \"Minyi Guo\",\n",
      "                        \"givenName\": \"Minyi\",\n",
      "                        \"surname\": \"Guo\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13xI8B2zWrH\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Nonvolatile Memory\",\n",
      "                    \"Encryption\",\n",
      "                    \"Authentication\",\n",
      "                    \"Memory Management\",\n",
      "                    \"Random Access Memory\",\n",
      "                    \"Non Volatile Memories\",\n",
      "                    \"Hardware Security\",\n",
      "                    \"Encryption\",\n",
      "                    \"Authentication\"\n",
      "                ],\n",
      "                \"title\": \"ARSENAL: Architecture for Secure Non-Volatile Memories\",\n",
      "                \"abstract\": \"Whereas data persistence in non-volatile memories (NVMs) enables instant data recovery (IDR) in the face of power/system failures, it also exposes NVMs to data confidentiality and integrity attacks. Counter mode encryption and Merkle Tree authentication are established measures to thwart data confidentiality and integrity attacks, respectively, in NVMs. However, these security mechanisms require high overhead atomic security meta-data updates on every write-back in order to support IDR in NVMs. This increases memory traffic and negatively impacts system performance and memory lifetime. Architecture for Secure Non-Volatile Memories (ARSENAL) is an IDR-preserving, low cost, high performance security solution that protects NVM systems against data confidentiality and integrity attacks. ARSENAL synergistically integrates (i) Smart Writes for Faster Transactions (SWIFT) , a novel technique to reduce the performance overhead of atomic security meta-data updates on every write-back, with (ii) Terminal BMT Updates (TBU), a novel BMT-consistency-preserving technique, to facilitate IDR in the face of power/system failures. Our evaluations show that on average, ARSENAL improves system performance (measured in IPC) by 2.26$\\\\times$  (4 $\\\\times$ ), reduces memory traffic overhead by 1.47 $\\\\times$ (1.88$\\\\times$ ), and improves memory lifetime by 2$\\\\times$  (3.5 $\\\\times$ ) in comparison to conventional IDR-preserving 64-bit (128-bit) encryption+authentication.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Electrical and Computer Engineering, University of Pittsburgh, Pittsburgh, PA, USA\",\n",
      "                        \"fullName\": \"Shivam Swami\",\n",
      "                        \"givenName\": \"Shivam\",\n",
      "                        \"surname\": \"Swami\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Electrical and Computer Engineering, University of Pittsburgh, Pittsburgh, PA, USA\",\n",
      "                        \"fullName\": \"Kartik Mohanram\",\n",
      "                        \"givenName\": \"Kartik\",\n",
      "                        \"surname\": \"Mohanram\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"13xI8A8WyX3\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Sensitivity\",\n",
      "                    \"Benchmark Testing\",\n",
      "                    \"Random Access Memory\",\n",
      "                    \"Layout\",\n",
      "                    \"Arrays\",\n",
      "                    \"Guidelines\",\n",
      "                    \"Graph Processing\",\n",
      "                    \"Memory Level Parallelism\",\n",
      "                    \"Cache Hierarchy\"\n",
      "                ],\n",
      "                \"title\": \"Exploring Core and Cache Hierarchy Bottlenecks in Graph Processing Workloads\",\n",
      "                \"abstract\": \"Graph processing is an important analysis technique for a wide range of big data problems. The ability to explicitly represent relationships between entities gives graph analytics significant performance advantage over traditional relational databases. In this paper, we perform an in-depth data-aware characterization of graph processing workloads on a simulated multi-core architecture, find bottlenecks in the core and the cache hierarchy that are not highlighted by previous characterization work, and analyze the behavior of the specific application data type causing the corresponding bottleneck. We find that load-load dependency chains involving different application data types form the primary bottleneck in achieving a high memory-level parallelism in graph processing workloads. We also observe that the private L2 cache has a negligible contribution to performance, whereas the shared L3 cache has higher performance sensitivity. In addition, we present a study on the effectiveness of several replacement policies. Finally, we study the relationship between different graph algorithms and the access volumes to the different data types. Overall, we provide useful insights and guidelines toward developing a more optimized CPU-based architecture for high performance graph processing.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"University of California, Santa Barbara, CA, USA\",\n",
      "                        \"fullName\": \"Abanti Basak\",\n",
      "                        \"givenName\": \"Abanti\",\n",
      "                        \"surname\": \"Basak\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"University of California, Santa Barbara, CA, USA\",\n",
      "                        \"fullName\": \"Xing Hu\",\n",
      "                        \"givenName\": \"Xing\",\n",
      "                        \"surname\": \"Hu\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"University of California, Santa Barbara, CA, USA\",\n",
      "                        \"fullName\": \"Shuangchen Li\",\n",
      "                        \"givenName\": \"Shuangchen\",\n",
      "                        \"surname\": \"Li\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"University of California, Santa Barbara, CA, USA\",\n",
      "                        \"fullName\": \"Sang Min Oh\",\n",
      "                        \"givenName\": \"Sang Min\",\n",
      "                        \"surname\": \"Oh\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"University of California, Santa Barbara, CA, USA\",\n",
      "                        \"fullName\": \"Yuan Xie\",\n",
      "                        \"givenName\": \"Yuan\",\n",
      "                        \"surname\": \"Xie\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"14ZDKJtqPMQ\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Power System Management\",\n",
      "                    \"Monitoring\",\n",
      "                    \"Power Demand\",\n",
      "                    \"Voltage Control\",\n",
      "                    \"Hardware\",\n",
      "                    \"Software\",\n",
      "                    \"System On Chip\",\n",
      "                    \"Power Management Vulnerabilities\",\n",
      "                    \"Covert Channels\"\n",
      "                ],\n",
      "                \"title\": \"A New Class of Covert Channels Exploiting Power Management Vulnerabilities\",\n",
      "                \"abstract\": \"Effective runtime power management requires hardware activity to be tracked at a very fine granularity in both space and time in order to meet diverse workload performance requirements within a tight power budget. As the available instantaneous power budget itself represents a shared resource, this practically translates into finding the optimal allocation of the power budget among active tasks of execution. Covert communication over a previously unexplored class of channels thereby becomes possible, which forms the focus of this paper.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"University of Minnesota, Minneapolis, MN, USA\",\n",
      "                        \"fullName\": \"S. Karen Khatamifard\",\n",
      "                        \"givenName\": \"S. Karen\",\n",
      "                        \"surname\": \"Khatamifard\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"University of South Florida, Tampa, FL, USA\",\n",
      "                        \"fullName\": \"Longfei Wang\",\n",
      "                        \"givenName\": \"Longfei\",\n",
      "                        \"surname\": \"Wang\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"University of South Florida, Tampa, FL, USA\",\n",
      "                        \"fullName\": \"Selcuk Kose\",\n",
      "                        \"givenName\": \"Selcuk\",\n",
      "                        \"surname\": \"Kose\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"University of Minnesota, Minneapolis, MN, USA\",\n",
      "                        \"fullName\": \"Ulya R. Karpuzcu\",\n",
      "                        \"givenName\": \"Ulya R.\",\n",
      "                        \"surname\": \"Karpuzcu\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"14ZDLkaecbS\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Computer Architecture\",\n",
      "                    \"Skeleton\",\n",
      "                    \"Prefetching\",\n",
      "                    \"Substrates\",\n",
      "                    \"Resource Management\",\n",
      "                    \"Context\",\n",
      "                    \"Decoupled Look Ahead DLA Architectures\",\n",
      "                    \"Simultaneous Multi Threading SMT\",\n",
      "                    \"Single Thread Performance\"\n",
      "                ],\n",
      "                \"title\": \"Bootstrapping: Using SMT Hardware to Improve Single-Thread Performance\",\n",
      "                \"abstract\": \"Decoupled look-ahead (DLA) architectures have been shown to be an effective way to improve single-thread performance. However, a default implementation requires an additional core. While an SMT flavor is possible, a naive implementation is inefficient and thus slow. In this paper, we propose an optimized implementation called Bootstrapping that makes DLA just as effective on a single (SMT) core as using two cores. While fusing two cores can improve single-thread performance by 1.23x, Bootstrapping provides a speedup of 1.51.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Electrical and Computer Engineering, University of Rochester, Rochester, NY, USA\",\n",
      "                        \"fullName\": \"Sushant Kondguli\",\n",
      "                        \"givenName\": \"Sushant\",\n",
      "                        \"surname\": \"Kondguli\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Electrical and Computer Engineering, University of Rochester, Rochester, NY, USA\",\n",
      "                        \"fullName\": \"Michael Huang\",\n",
      "                        \"givenName\": \"Michael\",\n",
      "                        \"surname\": \"Huang\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"14ZDLbCyHtu\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Encryption\",\n",
      "                    \"Computer Architecture\",\n",
      "                    \"Phase Change Materials\",\n",
      "                    \"Microprocessors\",\n",
      "                    \"Reliability\",\n",
      "                    \"Error Correction\",\n",
      "                    \"Emerging Memories\",\n",
      "                    \"Reliability\",\n",
      "                    \"Stuck At Faults\",\n",
      "                    \"And Error Correction\"\n",
      "                ],\n",
      "                \"title\": \"Counter Advance for Reliable Encryption in Phase Change Memory\",\n",
      "                \"abstract\": \"The use of hardware encryption and new memory technologies such as phase change memory (PCM) are gaining popularity in a variety of server applications such as cloud systems. While PCM provides energy and density advantages over conventional DRAM memory, it faces endurance challenges. Such challenges are exacerbated when employing memory encryption as the stored data is essentially randomized, losing data locality and reducing or eliminating the effectiveness of energy and endurance aware encoding techniques. This results in increasing dynamic energy consumption and accelerated wear out. In this paper we propose <italic>counter advance</italic>, a technique to leverage the process of encryption to improve reliability and lifetime while maintaining low-energy and low-latency operation. Counter advance is compatible with standard error-correction codes (ECC) and error correction pointers (ECP), the standard for mitigating endurance faults in PCM. Counter advance achieves the same fault tolerance using three ECP pointers for a <inline-formula><tex-math notation=\\\"LaTeX\\\">$10^{-4}$</tex-math><alternatives> <inline-graphic xlink:href=\\\"kline-ieq1-2861012.gif\\\"/></alternatives></inline-formula> cell failure rate compared to the leading approach to consider energy savings and reliability for encrypted PCM (SECRET) using five ECP pointers. At a failure rate of <inline-formula><tex-math notation=\\\"LaTeX\\\">$10^{-2}$</tex-math><alternatives> <inline-graphic xlink:href=\\\"kline-ieq2-2861012.gif\\\"/></alternatives></inline-formula>, counter advance can achieve an uncorrectable bit error rate (UBER) of 10<inline-formula><tex-math notation=\\\"LaTeX\\\">$^{-10}$</tex-math><alternatives> <inline-graphic xlink:href=\\\"kline-ieq3-2861012.gif\\\"/></alternatives></inline-formula>, compared to <inline-formula> <tex-math notation=\\\"LaTeX\\\">${&lt;}10^{-4}$</tex-math><alternatives> <inline-graphic xlink:href=\\\"kline-ieq4-2861012.gif\\\"/></alternatives></inline-formula> for SECRET, using six ECP pointers. This leads to a lifetime improvement of 3.8&#x00D7; while maintaining comparable energy consumption and access latency.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Electrical and Computer Engineering, University of Pittsburgh, PA, USA\",\n",
      "                        \"fullName\": \"Donald Kline\",\n",
      "                        \"givenName\": \"Donald\",\n",
      "                        \"surname\": \"Kline\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Computer Science, University of Pittsburgh, Pittsburgh, PA, USA\",\n",
      "                        \"fullName\": \"Rami Melhem\",\n",
      "                        \"givenName\": \"Rami\",\n",
      "                        \"surname\": \"Melhem\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Electrical and Computer Engineering, University of Pittsburgh, PA, USA\",\n",
      "                        \"fullName\": \"Alex K. Jones\",\n",
      "                        \"givenName\": \"Alex K.\",\n",
      "                        \"surname\": \"Jones\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"14ZDLZxpcEU\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Random Access Memory\",\n",
      "                    \"Graphics Processing Units\",\n",
      "                    \"Resource Management\",\n",
      "                    \"Arrays\",\n",
      "                    \"Memory Management\",\n",
      "                    \"Hardware\",\n",
      "                    \"DRAM Cache\",\n",
      "                    \"GPGPU\",\n",
      "                    \"CPU GPU Communication\",\n",
      "                    \"Store Before Load\",\n",
      "                    \"Tagless\"\n",
      "                ],\n",
      "                \"title\": \"ReDRAM: A Reconfigurable DRAM Cache for GPGPUs\",\n",
      "                \"abstract\": \"Hardware-based DRAM cache techniques for GPGPUs propose to use GPU DRAM as a cache of the host (system) memory. However, these approaches do not exploit the opportunity of allocating store-before-load data (data that is written before being read by GPU cores) on GPU DRAM that would save multiple CPU-GPU transactions. In this context, we propose ReDRAM, a novel memory allocation strategy for GPGPUs which re-configures GPU DRAM cache as a heterogeneous unit. It allows allocation of store-before-load data directly onto GPU DRAM and also utilizes it as a cache of the host memory. Our simulation results using a modified version of GPGPU-Sim show that ReDRAM can improve performance for applications that use store-before-load data by 57.6 percent (avg.) and 4.85x (max.) when compared to the existing proposals on state-of-the-art GPU DRAM caches.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Indian Institute of Technology Bhubaneswar, Bhubaneswar, Odisha, India\",\n",
      "                        \"fullName\": \"Debiprasanna Sahoo\",\n",
      "                        \"givenName\": \"Debiprasanna\",\n",
      "                        \"surname\": \"Sahoo\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Indian Institute of Technology Bhubaneswar, Bhubaneswar, Odisha, India\",\n",
      "                        \"fullName\": \"Swaraj Sha\",\n",
      "                        \"givenName\": \"Swaraj\",\n",
      "                        \"surname\": \"Sha\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Indian Institute of Technology Bhubaneswar, Bhubaneswar, Odisha, India\",\n",
      "                        \"fullName\": \"Manoranjan Satpathy\",\n",
      "                        \"givenName\": \"Manoranjan\",\n",
      "                        \"surname\": \"Satpathy\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Indian Institute of Technology Madras, Chennai, Tamil Nadu, India\",\n",
      "                        \"fullName\": \"Madhu Mutyam\",\n",
      "                        \"givenName\": \"Madhu\",\n",
      "                        \"surname\": \"Mutyam\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"14ZDLF7qexa\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Registers\",\n",
      "                    \"Microarchitecture\",\n",
      "                    \"Hardware\",\n",
      "                    \"Proposals\",\n",
      "                    \"Cryptography\",\n",
      "                    \"Pipelines\",\n",
      "                    \"Productivity\",\n",
      "                    \"Dynamic Scripting Language\",\n",
      "                    \"Interpreter\",\n",
      "                    \"Operand Access\",\n",
      "                    \"Microarchitectural Support\"\n",
      "                ],\n",
      "                \"title\": \"VMOR: Microarchitectural Support for Operand Access in an Interpreter\",\n",
      "                \"abstract\": \"Dynamic scripting languages become very popular for high productivity. However, many of these languages have significant runtime overheads because they employ interpreter-based virtual machines. One of the major overheads for the interpreter is derived from operand accesses, which significantly increase memory accesses. We propose VMOR, microarchitectural support for the operand accesses in the interpreter. VMOR remaps operand values into floating-point physical registers, which are rarely used in the interpreter, and thus, VMOR effectively reduces the memory accesses.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Kyushu University, Fukuoka, Fukuoka Prefecture, Japan\",\n",
      "                        \"fullName\": \"Susumu Mashimo\",\n",
      "                        \"givenName\": \"Susumu\",\n",
      "                        \"surname\": \"Mashimo\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Nagoya University, Nagoya, Aichi Prefecture, Japan\",\n",
      "                        \"fullName\": \"Ryota Shioya\",\n",
      "                        \"givenName\": \"Ryota\",\n",
      "                        \"surname\": \"Shioya\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Kyushu University, Fukuoka, Fukuoka Prefecture, Japan\",\n",
      "                        \"fullName\": \"Koji Inoue\",\n",
      "                        \"givenName\": \"Koji\",\n",
      "                        \"surname\": \"Inoue\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"14ZDLvYzhMk\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Prefetching\",\n",
      "                    \"Embedded Systems\",\n",
      "                    \"Bandwidth\",\n",
      "                    \"Computer Architecture\",\n",
      "                    \"Hardware\",\n",
      "                    \"Device Drivers\",\n",
      "                    \"Data Transfer\",\n",
      "                    \"Cache\",\n",
      "                    \"Embedded Processor\",\n",
      "                    \"Ethernet\",\n",
      "                    \"Internet Of Things\"\n",
      "                ],\n",
      "                \"title\": \"Semi-Coherent DMA: An Alternative I/O Coherency Management for Embedded Systems\",\n",
      "                \"abstract\": \"Many modern embedded CPUs adopt Non-Coherent DMA (NC-DMA) over Coherent DMA (C-DMA) because of simplicity. An NC-DMA design, however, requires a CPU device driver to explicitly invalidate or flush a wide range of cache space. When an I/O DMA device writes data to a main memory region, the CPU needs to invalidate the cache space corresponding to the same memory region twice: (1) to prevent dirty cache lines from overwriting the DMA data and (2) to remove any cache lines prefetched before the DMA is done. In this work, we first show that such explicit invalidations consume 31 percent of CPU cycles, limiting the data transfer throughput of a high-speed network interface card (NIC) when receiving network packets. Second, we propose a Semi-Coherent DMA (SC-DMA) architecture for improving the efficiency of NC-DMA with a slight modification to the hardware. Specifically, our SC-DMA records the DMA region and prohibits any data that is prefetched from the region from entering the cache, reducing nearly 50 percent of the unnecessary invalidations. Lastly, we identify several software optimizations that can substantially reduce excessive cache invalidations prevalent in NIC drivers. Our evaluation with NVIDIA Jetson TX2 shows that our proposed SC-DMA design with the NIC driver optimizations can improve the NIC data transfer throughput by up to 53.3 percent.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA\",\n",
      "                        \"fullName\": \"Seungwon Min\",\n",
      "                        \"givenName\": \"Seungwon\",\n",
      "                        \"surname\": \"Min\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA\",\n",
      "                        \"fullName\": \"Mohammad Alian\",\n",
      "                        \"givenName\": \"Mohammad\",\n",
      "                        \"surname\": \"Alian\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA\",\n",
      "                        \"fullName\": \"Wen-Mei Hwu\",\n",
      "                        \"givenName\": \"Wen-Mei\",\n",
      "                        \"surname\": \"Hwu\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA\",\n",
      "                        \"fullName\": \"Nam Sung Kim\",\n",
      "                        \"givenName\": \"Nam Sung\",\n",
      "                        \"surname\": \"Kim\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"14ZDMp3jIys\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Registers\",\n",
      "                    \"Image Processing\",\n",
      "                    \"Instruction Sets\",\n",
      "                    \"Microsoft Windows\",\n",
      "                    \"Graphics Processing Units\",\n",
      "                    \"Two Dimensional Displays\",\n",
      "                    \"Computer Architecture\",\n",
      "                    \"GP Us\",\n",
      "                    \"Spatial Image Processing Filters\",\n",
      "                    \"Neighbor Data Exchange\",\n",
      "                    \"Inter Core Communication\"\n",
      "                ],\n",
      "                \"title\": \"Neda: Supporting Direct Inter-Core Neighbor Data Exchange in GPUs\",\n",
      "                \"abstract\": \"Image processing applications employ various filters for several purposes, such as enhancing the images and extracting the features. Recent studies show that filters in image processing applications take a substantial amount of the execution time, and it is crucial to boost their performance to improve the overall performance of the image processing applications. Image processing filters require a significant amount of data sharing among threads which are in charge of filtering neighbor pixels. Graphics Processing Units (GPUs) attempt to satisfy the demand of data sharing by providing the scratch-pad memory, shuffle instructions, and on-chip caches. However, we observe that these mechanisms are insufficient to provide a fast and energy-efficient neighbor data sharing for the image processing filters. In this paper, we propose a new hardware/software co-design mechanism for GPUs, to effectively provide a fast and energy-efficient register-level neighbor data sharing for the image filters. We propose a neighbor data exchange mechanism, called <italic>Neda</italic>, that adds a register to each streaming processor (SP) which can be accessed by its neighboring SPs. Our experimental results show that <italic>Neda</italic> improves the performance and energy consumption by 12.4 and 13.5 percent, on average, respectively, compared to the NVIDIA SDK implementation of image processing filters. Moreover, <italic>Neda</italic>&#x0027;s performance is within 9.3 percent of the ideal GPU with zero latency neighbor data exchange capability.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Computer Engineering, Sharif University of Technology, Tehran, Iran\",\n",
      "                        \"fullName\": \"Negin Nematollahi\",\n",
      "                        \"givenName\": \"Negin\",\n",
      "                        \"surname\": \"Nematollahi\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Computer Engineering, Sharif University of Technology, Tehran, Iran\",\n",
      "                        \"fullName\": \"Mohammad Sadrosadati\",\n",
      "                        \"givenName\": \"Mohammad\",\n",
      "                        \"surname\": \"Sadrosadati\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Computer Science School, Institute for Researches in Fundamental Sciences, Tehran, Iran\",\n",
      "                        \"fullName\": \"Hajar Falahati\",\n",
      "                        \"givenName\": \"Hajar\",\n",
      "                        \"surname\": \"Falahati\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Computer Engineering, Sharif University of Technology, Tehran, Iran\",\n",
      "                        \"fullName\": \"Marzieh Barkhordar\",\n",
      "                        \"givenName\": \"Marzieh\",\n",
      "                        \"surname\": \"Barkhordar\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Computer Engineering, Sharif University of Technology, Tehran, Iran\",\n",
      "                        \"fullName\": \"Hamid Sarbazi-Azad\",\n",
      "                        \"givenName\": \"Hamid\",\n",
      "                        \"surname\": \"Sarbazi-Azad\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"idPrefix\": \"ca\",\n",
      "                \"id\": \"14ZDKZbCacg\",\n",
      "                \"year\": \"2018\",\n",
      "                \"pubDate\": \"2018-07-01\",\n",
      "                \"keywords\": [\n",
      "                    \"Multicore Processing\",\n",
      "                    \"System On Chip\",\n",
      "                    \"Interference\",\n",
      "                    \"Hardware\",\n",
      "                    \"Security\",\n",
      "                    \"Resilience\",\n",
      "                    \"Program Processors\",\n",
      "                    \"Multicore\",\n",
      "                    \"Hardware Resource Sharing\",\n",
      "                    \"Safety Critical Systems\",\n",
      "                    \"Resilience\",\n",
      "                    \"Security\",\n",
      "                    \"Side Channels\"\n",
      "                ],\n",
      "                \"title\": \"Multicore Resource Isolation for Deterministic, Resilient and Secure Concurrent Execution of Safety-Critical Applications\",\n",
      "                \"abstract\": \"Multicores increasingly deploy spatial execution of safety-critical applications that demand a deterministic, resilient, and secure environment to meet the safety standards. However, multicores aggressively share hardware resources that leads to non-deterministic performance due to destructive interference from concurrent applications. Resource sharing not only hinders efficient resilient execution, but also introduces security vulnerabilities due to information leakage on side-channels. This work proposes a novel multicore framework that constructs isolated clusters of cores for each concurrent application. It guarantees concurrent applications with deterministic performance, as well as an efficient execution environment for resiliency and security. Moreover, the framework allows dynamic re-sizing of cluster sizes for load balanced execution of concurrent applications. However, it leads to diminished isolation between clusters, which opens various performance&#x2013;resilience and performance&#x2013;security tradeoffs.\",\n",
      "                \"authors\": [\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Electrical and Computer Engineering, University of Connecticut, Storrs, CT, USA\",\n",
      "                        \"fullName\": \"Hamza Omar\",\n",
      "                        \"givenName\": \"Hamza\",\n",
      "                        \"surname\": \"Omar\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Electrical and Computer Engineering, University of Connecticut, Storrs, CT, USA\",\n",
      "                        \"fullName\": \"Halit Dogan\",\n",
      "                        \"givenName\": \"Halit\",\n",
      "                        \"surname\": \"Dogan\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"NXP Semiconductors Inc., Austin, TX, USA\",\n",
      "                        \"fullName\": \"Brian Kahne\",\n",
      "                        \"givenName\": \"Brian\",\n",
      "                        \"surname\": \"Kahne\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"affiliation\": \"Department of Electrical and Computer Engineering, University of Connecticut, Storrs, CT, USA\",\n",
      "                        \"fullName\": \"Omer Khan\",\n",
      "                        \"givenName\": \"Omer\",\n",
      "                        \"surname\": \"Khan\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(body, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### articleId로 id, keywords, pubDate, title, year 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.post(\"https://csdl-api.computer.org/api/v1/graphql\", \n",
    "                      json={\n",
    "                          \"variables\":{\"articleId\":\"13rRUwwslBG\"},\n",
    "                          \"query\":\"query ($articleId: String!) { articleById(articleId: $articleId) { id keywords pubDate title year } }\"\n",
    "                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": {\n",
      "        \"articleById\": {\n",
      "            \"id\": \"13rRUwwslBG\",\n",
      "            \"keywords\": [\n",
      "                \"Nonvolatile Memory\",\n",
      "                \"Random Access Memory\",\n",
      "                \"Encryption\",\n",
      "                \"Computer Architecture\",\n",
      "                \"System On Chip\",\n",
      "                \"Oblivious RAM\",\n",
      "                \"Non Volatile Memory\",\n",
      "                \"Memory Security\"\n",
      "            ],\n",
      "            \"pubDate\": \"2018-07-01\",\n",
      "            \"title\": \"LEO: Low Overhead Encryption ORAM for Non-Volatile Memories\",\n",
      "            \"year\": \"2018\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(body, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
